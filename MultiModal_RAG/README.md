# Multi Modal Hybrid RAG
![hybrid_multi_v3](https://github.com/user-attachments/assets/80c26821-085a-4554-bb70-53df62f7f516)


## Demo Videoüé•

<h3>üìπ Projemin Tanƒ±tƒ±m Videosu</h3>
<video src="https://github.com/user-attachments/assets/74700deb-8570-4a2b-b137-ede0940e19b4" controls width="600">
  Tarayƒ±cƒ±nƒ±z video √∂ƒüesini desteklemiyor.
</video>


https://github.com/user-attachments/assets/74700deb-8570-4a2b-b137-ede0940e19b4




## Overviewüîé

This project demonstrates an advanced Retrieval-Augmented Generation (RAG) system capable of answering questions based on information extracted from multiple sources within a document: standard text, structured tables, and images. It leverages a hybrid retrieval approach combining keyword search (BM25) and semantic search (FAISS with Google Embeddings) to find the most relevant context, which is then fed to Google's Gemini model to generate accurate, grounded answers. The system includes specific handling for table data extracted using **Azure Document Analysis** and image descriptions generated by Gemini Vision. A user-friendly interface is provided using Gradio.

## Features‚öôÔ∏è

*   **Multi-Modal Data Handling:** Processes text from PDFs, structured table data (from JSON), and image content.
*   **Table Extraction:** Utilizes pre-processed table data extracted via `Azure Document Analysis` from `Document Intelligence Studio` (provided as a JSON file).
*   **Image Understanding:** Uses Gemini Vision (`gemini-2.0-flash`) to generate descriptions of images within the document context.
*   **PDF Parsing:** Loads and splits PDF document text into manageable chunks using LangChain.
*   **Hybrid Retrieval:** Employs an `EnsembleRetriever` combining:
    *   **BM25:** Efficient keyword-based retrieval for text and table data.
    *   **FAISS Vector Store:** Semantic similarity search using Google's `embedding-001` model for text and image descriptions.
*   **Generative Answering:** Uses Google's `gemini-2.0-flash` model with a specific system prompt to generate answers grounded in the retrieved context, including citations (page numbers or table identifiers).
*   **Gradio Interface:** Provides a simple web UI for users to input queries and receive answers.

## WorkflowüîÄ

1.  **Load Environment Variables:** Loads the `GEMINI_API_KEY` from a `.env` file.
2.  **Table Data Processing:**
    *   Loads table structure data from a JSON file (generated by Azure Document Analysis).
    *   `extract_infos`: Parses the JSON to extract individual cell content, row/column indices, and page numbers.
    *   `flatten_table`: Groups cells by table ID and formats them into descriptive strings per row.
    *   `table_document`: Converts each table's flattened data into a LangChain `Document` object with appropriate metadata (table ID, page label).
3.  **Image Data Processing:**
    *   `get_image_description`: Sends a specified image file to the Gemini Vision model to get a textual description.
    *   Converts the description into a LangChain `Document` with page number metadata.
4.  **PDF Text Processing:**
    *   `parse_split_pdf`: Loads the specified PDF file using `PyPDFLoader`.
    *   Splits the document text into overlapping chunks using `RecursiveCharacterTextSplitter`.
5.  **Retriever Setup:**
    *   `ensemble_retriever`: Initializes:
        *   A `BM25Retriever` using the PDF text chunks and table documents.
        *   A `FAISS` vector store and retriever using the PDF text chunks and image description documents, embedded with `GoogleGenerativeAIEmbeddings`.
        *   An `EnsembleRetriever` combining BM25 and FAISS retrievers with equal weighting.
6.  **Question Answering:**
    *   `get_answer`:
        *   Takes a user query.
        *   Uses the `hybrid_retriever` to fetch relevant documents (text chunks, table data, image descriptions).
        *   Constructs a context string from the retrieved documents, including metadata (page/table info).
        *   Creates a system prompt instructing Gemini to answer based *only* on the provided context and to cite sources.
        *   Calls the Gemini model to generate the final answer.
7.  **Web Interface:**
    *   `main`: Orchestrates the data loading, processing, and retriever setup.
    *   Initializes and launches a Gradio interface for user interaction.

## Behind The Logic üí≠
Most parsing libraries struggle to extract tables or images without losing critical information because of limitations in their parsing algorithms.

When raw table data is directly extracted (for example, in JSON format), keyword search (like BM25) becomes very effective for answering specific table-related questions.

On the other hand, vector embeddings often struggle to handle fine-grained queries about specific rows or columns in tables, making them less accurate for structured data retrieval.

However, for questions related to images or text documents, semantic retrieval (based on vector similarity) works much better, capturing the meaning even when the wording differs.

Therefore, hybrid retrieval ‚Äî combining keyword-based and semantic-based retrievers ‚Äî ensures that:

* Table-related queries benefit from precise keyword matching.

* Image and text-related queries benefit from semantic understanding.

This approach provides a balanced and robust system that handles different query types effectively across various data modalities.
